\section{Overview of risk factor}
\subsection{Defining Risk} \label{Define Risk}
The judgement of risk related factors is a difficult concept to define and apply mathematical principals in order to construct a logical value. In day to day life risk is a particularly easy thing to identify. It is easy to define whether an event has aspects of high or low risk. However, it is a much more difficult parameter to breakdown and portray in mathematical terminology. Furthermore, this software is proposing a technique that focuses on previously neglected considerations. Therefore logic has been applied to define the weights of risk in many cases due to a lack of prior study and research. As discussed in chapter 4, a lot of risks come from the context of the scenario. Therefore, even though this can be mathematically defined, it is important to accept some limitations with the rational presented within this section. The supposition of logic in many cases has not been implemented with supporting research due to a lack of prior investigation. It is even more important to point out that people can not agree on the definition of a risk as \citeauthor{fischhoff1984defining} states 'The focal ingredient in all this has been concern over risk. Yet, the meaning of "risk" has always been fraught' (\cite{fischhoff1984defining}).


The body of the risk factor was made up of two distinct partitions. The breakdown of this value is made up from the first partition; 90\% from the formula itself. The formula itself will be discussed in section \ref{The Formula}. The second partition is comprised from two smaller sub-partitions and makes up the remaining 10\%. This is comprised from historical data gathered within the database. The two sub-partitions making up the remaining 10\%  have separate weights values. The first is data collected from the last 30 days and given a 75\% weight, the second is data collected from all time and given a weight of 25\%.

The use of the historical data is to try an give the system some idea of context, as it helps the system see if an IP has shown up and been reported in another log file. A heavier weighing is given to the last 30 days as described above; this is to try and assess if the IP is currently or actively attacking other websites. In addition to this, IPs sometimes change; this is why after 30 days a lesser weighing is given to the IP. It would be appropriate that this factor still forms part of the calculation. This is due to the fact that an IP may be used in rotation therefore, it may be quite for a while and then begin attacking websites again. This is supported in the following article that reiterates the importance of the age of Data sets (\cite{knowledge}).

Users have to manually report suspicious IP addresses; this was a design decision that was hard to make due to the opposing views of the literature. There is an argument that the IPs should be automatically reported to the system and this would have gave the system more data however. However, it all comes back to context in which case a human is better placed to judge and do so more accurately than any mathematical generalisation could. A human could appraise a variety of factors that a computer could not compensate for. An example could be presented where a user's personal IP would show up more frequently than any other traffic instance. This would potentially lead to a high risk related tag. This reinforces the case that there was the chance that non suspicious IPs could be flagged and reported to the system. 

As previously discussed, 90\% of the weighing is derived from the log files. This may be regarded as a particularly heavy weighing. The rational behind this was that the activity on a website by IP could be assessed independently of other websites. The high weighing of the log file means that an IP, even if not known to the data base, can still achieve a very high risk factor therefore, giving more user feedback about their log file. In the next section, the exact formula will be discussed with justifications of the inner-workings of the formula. (REWORD)
%.Why we use historical data
%.the fact that users have to report the data
%.Why some some elements weight more than others.

%end with intro to formullaz