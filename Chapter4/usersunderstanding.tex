\section{Introduction}
In previous chapters it has been shown, how attacks can be identified and mitigated using algarthims and other machine learning. The majority of research approaching the subject of the detection or mitigation of malicous traffic have focused upon programmed methods of automated detection. To date there is a distinct lack of data on the human element for detection methodology, two main areas will be assessed in the role human in the system.

\section{User understanding} \label{UI Theory}
One of the areas that is often looked at when talking about identifying threats is not only the computers ability to model threat vectors, it is also the ability for the user to manually identify the threats and appropriately classify them. Theory would suggest that people with a Cyber security background would be able to better identify threats. In order to design the software and an appropriate user interface, it is important to look at the human factors involved as they can act in an unpredictable manner due to the differences in cognitive abilities. This chapter will look into the key factors that effect user understanding in order to better understand the principals involved in building a suitable user interface. It will also debate the utilisation of a human element within the software as an overall decision maker versus a completely AI automated system. 


Crannor stated in 2008 'Many secure systems rely on a “human in the loop” to perform security-critical functions. However, humans often fail in their security roles. Whenever possible, secure system designers should find ways of keeping humans out of the loop.' (\cite{cranor2008framework}) This should be taken into account when designing the system. Crannor's take on the human element within a security protocol promotes the integration of a feature in the software to automatically block suspicious IP instances. However, it has been identified from prior papers that many AI systems based around formulaic rational can be generalised, and have a degree of uncertainty and error (\cite{kim2008slow}). Due to the conflicting array of arguments within the field regarding whether or not keeping a human factor within the loop for analysis is beneficial or not. As will be explored in the section \ref{Define Risk}, it would be logical to assume that risk is difficult concept to define. This would therefore make a total AI build both impractical to build and potentially a system fraught with uncertainty.

It was suggested within Noam Ben-Asher's 2015 paper that effective design of information security systems that support the work of the human security analyst, may benefit from a better understanding of the capabilities and limitations of the human decision maker who uses them (\cite{ben2015effects}). For this reason it is imperative to design a user interface that promotes understanding of the software during the synthesis. It also fortifies the need for further reading into studies that assess human computer interaction and decision making in general. Noam Ben-Asher's 2009 publication he stated 'for users to accept security mechanisms, they must be aware of the security threats and understand the importance of security.' (\cite{ben2009experimental})

Ben-Asher's 2015 study attempts to see if there is a link between cyber security knowledge and the ability to detect attacks and or malicious network traffic. The experiment comprised of two seperate groups, an expert group comprised of 20 and, a novice group comprised of 55 university participants. Novice participants were given 10 scenarios containing 20 network events in order to determine the maliciousness or lack of in each case. Experts were given a smaller load of 3 scenarios containing 20 network events and similarly asked to identify threats. These 20 events were chosen at random from a large pool of events which was reflective of the size of each candidate group. The reason given by the researchers for the reduced expectations for expert participants was a concern over their willingness to participate, taking them away from dedicated work hours.   

In order to better understand the differences in efficiency between an expert and novice in terms of the ability to identify incoming malicious traffic the research undertaken by \citeauthor{ben2015effects} was reviewed. In this research the author set up testing of two distinct categories of individual to asses their performance in identifying malicious network activity. The first group of test subjects had advanced knowledge in the field of cyber security and, the second group were novices' having no prior knowledge of network or cyber security methodology. 

As part of this testing the candidates were examined on their prior knowledge in the areas of theory and understanding on the definitions of attacks. In review of this literature this was an excellent way of validating the candidates authenticity as candidates for each test group. The candidates were then evaluated in their capacity to identify malicious network activity in a practical manor and given a large pool of network events to assess. Novice participants were given 10 scenarios containing 20 network events in order to determine the maliciousness or 'lack of' in each case. Experts were given a smaller load of 3 scenarios containing 20 network events and were similarly asked to identify threats. These 20 events were chosen at random from a large pool of events which was reflective of the size of each candidate group (\cite{ben2015effects}). The reason given given by the researchers for the reduced expectations for expert participants was a concern over their willingness to participate.

It could be argued that there are three weaknesses with the study conducted by \citeauthor{ben2015effects}. The first issue is that the candidates were given a time limit in order to answer questions with a timer showing them how long they had to respond; this may have introduced a stress factor to the scenario that was not required for the overall purpose of the research. Research by Keinan in 1987, showed that elevated stress levels incurred during timed conditions lead to more errors (\cite{Keinan}). This would indicate that the implementation of a system that does not include a time constraint is important, in the case of Ben-Ashers study, these stress factors were increased every 10 seconds. This is due to the fact that one of the goals of our software is that website owners can use it themselves. The website owners may not have much, if any cyber security knowledge, however may have good IT skills. The novices would have been under increased stress as they had no prior experience assessing cyber security threats thus, affecting the results of the experiment.

Another criticism that could be made is the fact that the expert group completed the assessment online whereas the novices were tested in a controlled and proctored environment. It could be argued that not testing them in the same environmental conditions invalidates the research. A study by \citeauthor{russell2003computer} reported that students who are comfortable writing on computer actually do better on computerized writing exams (\cite{russell2003computer}). Which builds upon the criticism of the study in terms of the advantages that the Cyber security experts had in this testing. The overall ecological validity becomes compromised here as, the environments do not mirror a real life setting \cite{bryman_2016}. Thus, the comparative element of these results is not achievable due to external factors influencing these individuals differently which, can effect elements such as stress.

A third criticism that could be made, of this paper is the different amounts of material that the candidate types were given to assess. It could be argued that fatigue took place during critical stages of the assessment for the novice group as they were tasked with a work load over 300\% larger than the experts. If the researcher was correct in his assumptions that an increased work load would have deterred the cyber security specialists from participating in the experiment, then the work load of both groups should have been equalised. Therefore a reasonable work around could have been implemented by reducing the work load of the non-specialists to the lower expectations of that of the experts. It could therefore, be argued that this paper lacks internal validity, which as Bryman (2016) suggests "If we suggest that x causes y, can we be sure that x is responsible for the variation for y and not something else" (\citeauthor{bryman_2016} \citeyear{bryman_2016}).

Due to the different workloads and stress factors in the different sample groups, it becomes apparent when applying \citeauthor{bryman_2016} conclusions on internal validity that some major flaws exist in this research. It has not been proven in definitive terms that the users cyber security knowledge impacts the ability to identify security threats. The results of Ben-Asher's 2015 study suggests a almost equal result level for both groups. If the study was conducted with equal workloads and an equal environment, disregarding the likelihood of professionals taking part, then these results may have been identical. This in turn may have rendered the research non-applicable. The study does however suggest that a clear user interface will aid users in detecting attacks and therefore, when designing the software of a project, a clear user interface will be required. 